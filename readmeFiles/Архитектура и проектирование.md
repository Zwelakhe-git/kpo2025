**Конструирование ПО 2025**

## Архитектура и проектирование

**Тема:** Веб приложение для компании (Для Новостей)

**Масеко Звелаке
Ха Жа Кинь
Гюнеш Мустафа**

**Группа:** 5130904/30103

**1.**   **Характер нагрузки на сервис:**

**1.1.**         **Соотношение R/W нагрузки**

| **Раздел**                        | **Чтение**                 | **Запись**                      |
| --------------------------------- | -------------------------- | ------------------------------- |
| Новостной контент                 | 90%                        | 10% (редакторы, модераторы)     |
| Музыка/видео стриминг             | 95%                        | 5% (загрузка контента админами) |
| Продажа билетов                   | 70% (просмотр мероприятий) | 30% (бронирование, оплата)      |
| Услуги (маркетинг, дизайн и т.д.) | 60%                        | 40% (заявки, коммуникация)      |

**Общее соотношение: 79% R / 21% W**

 

**1.2.**         **Объемы трафика**

**Входящий трафик (к пользователям):**

●   **DAU:** 15 000 пользователей;

●   **Новости/Текст:** ~60 ГБ/день (15к пользователей * ~4 МБ данных статей, CSS, JS).

●   **Музыка:** ~150 ГБ/день (допустим, 20% пользователей слушают ~30 мин = ~50 МБ/пользователь → 3000 * 50 МБ).

●   **Видео (стриминг):** ~1 ТБ/день (для 2000 подписчиков, смотрящих в SD ~1 ГБ/день → 2000 * 500 МБ).

**Исходящий трафик (от пользователей):**

●   Незначительный, в основном загрузка аватарок и форма заявок с файлами.

 

**1.3.**         **Объемы дисковой системы**

●   Новости + метаданные: ~5 ГБ/год

●   Медиаконтент (видео + аудио): ~20 ТБ/год

●   База данных (транзакции, профили, билеты): ~1 ГБ/год

**2.**   **Первые две диаграммы из подхода** [**https://c4model.com/**](https://c4model.com/)

**2.1.**         **System Context Diagram (C4 Level 1)**

![image-20251008203223314](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203223314.png)



![image-20251008203238224](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203238224.png)

**2.2.**         **Container Diagram (C4 Level 2)**

![image-20251008203419463](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203419463.png)

![image-20251008203435416](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203435416.png)



**3.**   **Контракты API + Ожидаемые нефункциональные требования на время отклика**

**3.1.**          **Получение списка новостей:**

●   **Метод:** GET /api/v1/news

●   **Параметры:** 

**page** (number, optional)

**category** (string, optional)

**pageSize** (number, optional, default: 20)

●   **Ответ (200 OK):**

![image-20251008203535622](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203535622.png)

●   **Нефункциональные требования:**

**Время отклика (p95):** < 200 мс.

**Доступность (Availability):** > 99.9%.

**Пропускная способность:** > 1000 RPS.

**3.2.**          **Покупка билета**

●   **Метод****:** POST /api/v1/events/{eventId}/tickets

●   **Заголовки:** Authorization: Bearer <JWT>

●   **Тело запроса:**

![image-20251008203618909](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203618909.png)

●   **Ответ (201 Created):**

![image-20251008203636166](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203636166.png)

●   **Нефункциональные требования:**

**Время отклика (p95):** <2 секунды (из-за взаимодействия с платежным шлюзом).

**Согласованность данных:** Сильная (нельзя продать два билета на одно место).

**Безопасность:** PCI DSS compliance для любых операций с картами.



**4.**   **Схема базы данных + почему она выдержит нефункциональные требования**

![image-20251008203724190](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203724190.png)

![image-20251008203736598](C:\Users\ThunderPC\AppData\Roaming\Typora\typora-user-images\image-20251008203736598.png)

**5.1.**         **Почему схема выдержит нагрузку:**

●   **Индексы****:** Все PK, FK, email, published_at, event_id, user_id индексируются.

●   **Read Replica:** Все тяжелые SELECT (новости, поиск) идут на реплику.

●   **Кэш:** Redis кэширует списки статей, популярные страницы, сессии. 

●   **Нормализация:** Снижает избыточность данных и аномалии при обновлении.

●   **Шардирование:** При росте можно шардировать Events или Articles по category или дате.

**5.**   **Схема масштабирования сервиса при росте нагрузка 10 раз**

При росте до ~150 000 пользователей/день:

**5.1.**         **Фронтенд:**

●   CDN (Cloudflare, AWS CloudFront) для статики и медиа

●   SSR → ISR (Incremental Static Regeneration) для новостей

**5.2.**         **Бэкенд:**

●   Горизонтальное масштабирование микросервисов (Kubernetes)

●   API Gateway с rate limiting и circuit breaker

**5.3.**         **База данных:**

●   PostgreSQL → read replicas (3–5 шт.)

●   Миграция тяжёлых операций в ClickHouse (аналитика)

●   Кэширование через Redis Cluster

**5.4.**         **Медиа:**

●   HLS-стриминг через Cloudflare Stream или AWS MediaConvert + CloudFront

●   Автоматическое сжатие и транскодирование

**5.5.**         **Платежи:**

●   Асинхронная обработка через очередь (RabbitMQ/Kafka)

●   Идемпотентность запросов

**5.6.**         **Мониторинг:**

●   Prometheus + Grafana

●   Логи в ELK или Loki